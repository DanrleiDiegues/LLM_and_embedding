{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"--\"  \n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Create a model instance (using Gemini-Pro)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Hello, world!\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Example: Generate a response\n",
    "response = model.generate_content(\"Write a hello world message\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate each entry to 5,000 characters\n",
    "    text = text[:5000]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "\n",
    "    # We have fewer categories now, so re-calibrate the label encoding.\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = \"sci\"  # Class name should contain 'sci' to keep science categories\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          100\n",
       "sci.electronics    100\n",
       "sci.med            100\n",
       "sci.space          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          25\n",
       "sci.electronics    25\n",
       "sci.med            25\n",
       "sci.space          25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "@retry.Retry(timeout=300.0)\n",
    "def embed_fn(text: str) -> list[float]:\n",
    "    # You will be performing classification, so set task_type accordingly.\n",
    "    response = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\", content=text, task_type=\"classification\"\n",
    "    )\n",
    "\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "\n",
    "def create_embeddings(df):\n",
    "    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:06<00:00,  3.15it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train = create_embeddings(df_train)\n",
    "df_test = create_embeddings(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Re: Once tapped, your code is no good any more.\\n\\nIn article &lt;&gt;  (douglas craig holland) writes:\\n&gt;\\tWith E-Mail, if they can't break your PGP encryption, they'll just\\n&gt;call up one of their TEMPEST trucks and read the electromagnetic emmisions\\n&gt;from your computer or terminal.  Note that measures to protect yourself from\\n&gt;TEMPEST surveillance are still classified, as far as I know.\\n\\nNote that TEMPEST is the name of the shielding standard.  TEMPEST is not\\nthe name of the surveillance technique.\\n\\nKen Shirriff\\t\\t\\t\\t\\nDisclaimer: this is what I've heard and it's in the sci.crypt FAQ, so it's\\nprobably true but I can't guarantee it.  I'd like to know if I'm wrong.\\n</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0043086354, 0.014946195, -0.04718869, 0.038918644, 0.026516398, 0.07706348, 0.10642429, 0.049502425, -0.013975333, -0.018014356, 0.062174253, 0.05050502, 0.023072755, 0.033149973, 0.054371137, -0.0548496, 0.08523746, 0.047518972, -0.0003643629, -0.050271448, -0.025574224, 0.019547164, -0.009532954, 0.0051346673, -0.010429473, -0.0008891799, 0.0012947439, -0.0246474, 0.0068962136, -0.017097741, 0.03163274, 0.015851222, -0.018555803, -0.0083137825, 0.051839203, -0.0059056072, 0.0038899009, 0.021635285, 0.0025033378, -0.06797125, -0.047640763, -0.0012215399, -0.043856185, 0.06743114, -0.042062163, -0.026372904, -0.03635169, -0.058605645, -0.07490101, 0.01896286, -0.023904743, 0.032075237, -0.0017136263, 0.039858103, -0.008706433, -0.041990276, 0.019131372, -0.07795157, 0.0073262397, -0.06462448, -0.0042621507, -0.015266651, 0.03303322, -0.018320683, -0.010633533, -0.024478858, -0.02866816, 0.025612757, -0.05977793, -0.008514277, 0.01163799, 0.06699485, -0.041104812, 0.028408406, 0.02129292, -0.008280964, 0.0869091, -0.01033378, 0.044564925, 0.04092834, -0.034560334, -0.03273403, 0.041548397, -0.007906608, -0.008581105, -0.05207929, 0.029798444, 0.024593176, -0.07719749, -0.051054936, 0.07416974, 0.01987089, -0.030529829, 0.012194375, 0.06359984, -0.009392929, 0.01087187, -0.06341449, 0.04224102, 0.022851307, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>DES: init vector as additional key?\\n\\nThe recent discussion in this news group suggests that a key search attack  \\nagainst DES is quite feasible now. But normally DES is applied in CBC or CFB  \\nmode where one chooses a random init vector of 8 bytes. Questions:\\n\\n - Makes it sense to handle the init vector as an additional key? Then we have  \\na 56 + 64 = 120 bit key.\\n \\n - If yes: Is anything known about the security of this key scheme? Can we  \\nbreak it faster than by exhaustive search through the 120 bit key space?\\n\\n--\\nKlaus Pommerening\\nInstitut fuer Medizinische Statistik und Dokumentation\\nder Johannes-Gutenberg-Universitaet\\nObere Zahlbacher Strasse 69, W-6500 Mainz, Germany\\n</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0052515334, -0.024516884, -0.022230675, 0.03033998, 0.0034571097, 0.06945318, 0.07900606, 0.017766396, -0.011564752, -0.0055645434, 0.0800191, 0.028026406, 0.011098125, 0.003142284, 0.058238015, -0.06528971, 0.10194961, 0.025307294, 0.010203706, -0.039929863, -0.040476304, 0.0071391375, -0.0066721896, 0.024076223, -0.011510883, 0.014300542, 0.0074101, -0.034654137, 0.020016504, -0.011501476, 0.01991005, 0.030683937, -0.008233792, -0.032788854, 0.025400637, -0.016371952, 0.02223255, 0.033161785, -0.011772858, -0.04757878, -0.05254649, -0.008974971, -0.023268113, 0.032900754, -0.032418188, -0.03576506, -0.0005484355, -0.022237595, -0.074608274, 0.011349422, -0.013468872, 0.0011192947, -0.030095484, 0.024018854, 0.012187186, -0.010653717, 0.030060446, -0.019402646, 0.01535876, -0.066677265, 0.008329106, -0.013744917, 0.012467578, -0.012481877, 0.010764515, -0.023325682, -0.020720158, 0.010331271, -0.05240565, 0.0018682295, 0.05617261, 0.09089013, -0.027483238, 0.051388618, 0.0043779816, 0.02593068, 0.08645078, 0.0036815861, 0.054931894, 0.054556802, -0.029818267, -0.05374424, 0.05202867, 0.012696309, 0.01351062, -0.024774952, 0.013146285, -0.00841141, -0.053881302, -0.0060386676, 0.07039838, 0.057442598, -0.032227162, 0.036698375, 0.05217372, -0.013699033, 0.017393427, -0.11009749, 0.06170662, 0.019858098, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
       "1100                       Re: Once tapped, your code is no good any more.\\n\\nIn article <>  (douglas craig holland) writes:\\n>\\tWith E-Mail, if they can't break your PGP encryption, they'll just\\n>call up one of their TEMPEST trucks and read the electromagnetic emmisions\\n>from your computer or terminal.  Note that measures to protect yourself from\\n>TEMPEST surveillance are still classified, as far as I know.\\n\\nNote that TEMPEST is the name of the shielding standard.  TEMPEST is not\\nthe name of the surveillance technique.\\n\\nKen Shirriff\\t\\t\\t\\t\\nDisclaimer: this is what I've heard and it's in the sci.crypt FAQ, so it's\\nprobably true but I can't guarantee it.  I'd like to know if I'm wrong.\\n   \n",
       "1101  DES: init vector as additional key?\\n\\nThe recent discussion in this news group suggests that a key search attack  \\nagainst DES is quite feasible now. But normally DES is applied in CBC or CFB  \\nmode where one chooses a random init vector of 8 bytes. Questions:\\n\\n - Makes it sense to handle the init vector as an additional key? Then we have  \\na 56 + 64 = 120 bit key.\\n \\n - If yes: Is anything known about the security of this key scheme? Can we  \\nbreak it faster than by exhaustive search through the 120 bit key space?\\n\\n--\\nKlaus Pommerening\\nInstitut fuer Medizinische Statistik und Dokumentation\\nder Johannes-Gutenberg-Universitaet\\nObere Zahlbacher Strasse 69, W-6500 Mainz, Germany\\n   \n",
       "\n",
       "      Label Class Name  Encoded Label  \\\n",
       "1100     11  sci.crypt              0   \n",
       "1101     11  sci.crypt              0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Embeddings  \n",
       "1100  [-0.0043086354, 0.014946195, -0.04718869, 0.038918644, 0.026516398, 0.07706348, 0.10642429, 0.049502425, -0.013975333, -0.018014356, 0.062174253, 0.05050502, 0.023072755, 0.033149973, 0.054371137, -0.0548496, 0.08523746, 0.047518972, -0.0003643629, -0.050271448, -0.025574224, 0.019547164, -0.009532954, 0.0051346673, -0.010429473, -0.0008891799, 0.0012947439, -0.0246474, 0.0068962136, -0.017097741, 0.03163274, 0.015851222, -0.018555803, -0.0083137825, 0.051839203, -0.0059056072, 0.0038899009, 0.021635285, 0.0025033378, -0.06797125, -0.047640763, -0.0012215399, -0.043856185, 0.06743114, -0.042062163, -0.026372904, -0.03635169, -0.058605645, -0.07490101, 0.01896286, -0.023904743, 0.032075237, -0.0017136263, 0.039858103, -0.008706433, -0.041990276, 0.019131372, -0.07795157, 0.0073262397, -0.06462448, -0.0042621507, -0.015266651, 0.03303322, -0.018320683, -0.010633533, -0.024478858, -0.02866816, 0.025612757, -0.05977793, -0.008514277, 0.01163799, 0.06699485, -0.041104812, 0.028408406, 0.02129292, -0.008280964, 0.0869091, -0.01033378, 0.044564925, 0.04092834, -0.034560334, -0.03273403, 0.041548397, -0.007906608, -0.008581105, -0.05207929, 0.029798444, 0.024593176, -0.07719749, -0.051054936, 0.07416974, 0.01987089, -0.030529829, 0.012194375, 0.06359984, -0.009392929, 0.01087187, -0.06341449, 0.04224102, 0.022851307, ...]  \n",
       "1101     [0.0052515334, -0.024516884, -0.022230675, 0.03033998, 0.0034571097, 0.06945318, 0.07900606, 0.017766396, -0.011564752, -0.0055645434, 0.0800191, 0.028026406, 0.011098125, 0.003142284, 0.058238015, -0.06528971, 0.10194961, 0.025307294, 0.010203706, -0.039929863, -0.040476304, 0.0071391375, -0.0066721896, 0.024076223, -0.011510883, 0.014300542, 0.0074101, -0.034654137, 0.020016504, -0.011501476, 0.01991005, 0.030683937, -0.008233792, -0.032788854, 0.025400637, -0.016371952, 0.02223255, 0.033161785, -0.011772858, -0.04757878, -0.05254649, -0.008974971, -0.023268113, 0.032900754, -0.032418188, -0.03576506, -0.0005484355, -0.022237595, -0.074608274, 0.011349422, -0.013468872, 0.0011192947, -0.030095484, 0.024018854, 0.012187186, -0.010653717, 0.030060446, -0.019402646, 0.01535876, -0.066677265, 0.008329106, -0.013744917, 0.012467578, -0.012481877, 0.010764515, -0.023325682, -0.020720158, 0.010331271, -0.05240565, 0.0018682295, 0.05617261, 0.09089013, -0.027483238, 0.051388618, 0.0043779816, 0.02593068, 0.08645078, 0.0036815861, 0.054931894, 0.054556802, -0.029818267, -0.05374424, 0.05202867, 0.012696309, 0.01351062, -0.024774952, 0.013146285, -0.00841141, -0.053881302, -0.0060386676, 0.07039838, 0.057442598, -0.032227162, 0.036698375, 0.05217372, -0.013699033, 0.017393427, -0.11009749, 0.06170662, 0.019858098, ...]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input([input_size], name=\"embedding_inputs\"),\n",
    "            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,076</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │       \u001b[38;5;34m590,592\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_probs (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m3,076\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Derive the embedding size from observing the data. The embedding size can also be specified\n",
    "# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\n",
    "embedding_size = len(df_train[\"Embeddings\"].iloc[0])\n",
    "\n",
    "classifier = build_classification_model(\n",
    "    embedding_size, len(df_train[\"Class Name\"].unique())\n",
    ")\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.3341 - loss: 1.3755 - val_accuracy: 0.3600 - val_loss: 1.2940\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5885 - loss: 1.2275 - val_accuracy: 0.6200 - val_loss: 1.1684\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8309 - loss: 1.0611 - val_accuracy: 0.8300 - val_loss: 1.0125\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9623 - loss: 0.8723 - val_accuracy: 0.8400 - val_loss: 0.8535\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9136 - loss: 0.7155 - val_accuracy: 0.8800 - val_loss: 0.7204\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9376 - loss: 0.5405 - val_accuracy: 0.8700 - val_loss: 0.6458\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9625 - loss: 0.4223 - val_accuracy: 0.8900 - val_loss: 0.5342\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9678 - loss: 0.3292 - val_accuracy: 0.8900 - val_loss: 0.4732\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9734 - loss: 0.2601 - val_accuracy: 0.8800 - val_loss: 0.4346\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9639 - loss: 0.2272 - val_accuracy: 0.8700 - val_loss: 0.4187\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.1807 - val_accuracy: 0.8800 - val_loss: 0.3904\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9828 - loss: 0.1429 - val_accuracy: 0.9000 - val_loss: 0.3610\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.1342 - val_accuracy: 0.9100 - val_loss: 0.3468\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.1135 - val_accuracy: 0.9100 - val_loss: 0.3510\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.1104 - val_accuracy: 0.9200 - val_loss: 0.3387\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 0.0917 - val_accuracy: 0.9000 - val_loss: 0.3084\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9949 - loss: 0.0903 - val_accuracy: 0.9100 - val_loss: 0.3482\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9978 - loss: 0.0772 - val_accuracy: 0.9000 - val_loss: 0.3046\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 0.0743 - val_accuracy: 0.9100 - val_loss: 0.3035\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0535 - val_accuracy: 0.9300 - val_loss: 0.3079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train[\"Encoded Label\"]\n",
    "x_train = np.stack(df_train[\"Embeddings\"])\n",
    "y_val = df_test[\"Encoded Label\"]\n",
    "x_val = np.stack(df_test[\"Embeddings\"])\n",
    "\n",
    "# Specify that it's OK to stop early if accuracy stabilises.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "history = classifier.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance\n",
    "\n",
    "Use Keras <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\"><code>Model.evaluate</code></a> to calculate the loss and accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9283 - loss: 0.2809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9300000071525574, 'loss': 0.3079419732093811}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a custom prediction\n",
    "\n",
    "Now that you have a trained model with good evaluation metrics, you can try to make a prediction with new, hand-written data. Use the provided example or try your own data to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.019432709, -0.0134165445, -0.038569827, 0.027099848, 0.030647298, 0.0552539, 0.089664415, 0.040378496, -0.010588484, 0.009992522, 0.031105185, 0.041578043, 0.029177554, -0.0058882097, 0.049694806, -0.04701471, 0.08547439, 0.06041958, -0.041273843, -0.02578345, -0.0055946195, 0.018798409, -0.0111317085, 0.011139821, -0.0051660193, 0.030108875, 0.04181174, -0.012075451, 0.0108866645, -0.015594199, 0.017580828, 0.04662013, 0.04908052, -0.016169475, 0.051437464, 0.007593721, -0.0024948507, -0.010638129, 0.027199747, -0.07219817, -0.05390348, 0.022033947, -0.0032580693, 0.03200955, -0.04087985, -0.049519826, -0.05676126, -0.02587544, -0.06374949, 0.010307776, 0.0033229957, 0.057755854, -0.047802165, 0.0480191, 0.0029020114, -0.020711409, -0.0018620442, -0.038993567, 0.037544888, -0.093531534, -0.005849261, -0.024610138, 0.03038399, -0.010527783, -0.013461092, -0.053257346, -0.031193351, 0.03940577, -0.038611542, -0.0012961501, 0.002042963, 0.08961567, -0.04722155, 0.05110101, 0.025155822, -0.016308637, 0.033830713, 0.0062567685, 0.033400603, 0.057830025, -0.019287556, -0.033983026, 0.03766932, -0.0011553714, -0.031135539, -0.06833679, -0.01922105, 0.005850203, -0.073341966, -0.051009573, 0.0031484703, 0.027885664, -0.030361125, 0.0039537395, 0.04503863, -0.0036628635, 0.0039194734, -0.074071795, -0.011098811, 0.034248777, -0.026639879, 0.002732365, 0.05713699, -0.016771669, 0.046479695, 0.047446847, -0.02465378, 0.0043319836, -0.04727983, 0.04367712, 0.0015393835, -0.001314563, -0.028358141, -0.0036181107, -0.048532996, 0.03312514, 0.015936093, 0.036582083, 0.009461241, -0.044946752, 0.025015322, 0.08101833, 0.02031033, 0.009754299, 0.036107834, -0.0011179361, 0.0038329929, -0.033679765, 0.02950826, -0.042187933, 0.03106958, -0.10202598, -0.069456756, 0.036853917, -0.026639277, 0.033723664, 0.02246831, -0.024036735, -0.010618825, -0.0068174354, -0.0036340733, 0.0043698694, -0.060189743, 0.009557113, -0.0023327458, -0.040368255, 0.02153442, 0.03308467, 0.009457934, 0.025650708, 0.012158002, -0.028843075, -0.0010730156, 0.036428444, -0.08552, -0.01825338, 0.018576147, -0.02344646, 0.03794691, -0.016654212, -0.01446451, -0.0074672024, 0.017218383, 0.007043343, 0.00792165, -0.049899515, 0.009864239, -0.087781854, -0.033756137, -0.014795152, -0.0016632015, -0.024198765, -0.015141961, 0.03659975, 0.0031884147, -0.0013528303, 0.0085087465, -0.028671429, -0.014281888, -0.02284225, 0.022262963, 0.045389876, 0.00878628, -0.03653137, -0.022916555, -0.0064491425, -0.057524, 0.017201196, 0.04500523, 0.045416597, -0.008843437, -0.0052514584, -0.03119155, -0.033690605, -0.048361033, 0.008678555, 0.052982986, -0.06044745, 0.023905238, 0.006395196, 0.009440842, -0.0356033, 0.0020058076, -0.038680553, -0.028463557, 0.051014602, 0.02183042, -0.032457348, 0.023904795, 0.017257579, -0.044287063, -0.07480066, 0.012105293, 0.017509691, 0.013938047, 0.060208436, 0.02968526, -0.007035227, 0.050346874, -0.0046889554, -0.019877793, -0.0012278875, -0.023795292, 0.084887326, 0.004058922, -0.07980401, 0.0026595553, 0.028179491, -0.030790595, -0.044082828, 0.019117542, 0.060678337, -0.014456808, 0.010636579, -0.018026805, 0.031287007, 0.029559702, 0.007387214, 0.0004470112, 0.006553569, 0.012030128, -0.04449126, -0.022964062, -0.02901424, -0.004184123, 0.015299478, 0.06592324, -0.04847427, 0.011087912, -0.00862393, -0.00588199, 0.0017598934, -0.0821454, 0.034381736, 0.014702816, 0.0069361753, 0.039837793, 0.010821013, -0.017933127, 0.003876549, 0.046574343, 0.002357265, 0.008704986, -0.011614067, -0.03786873, -0.041624695, -0.020404872, -0.019786542, -0.006599384, -0.01733682, 0.024125779, -0.02989378, 0.0025192841, -0.017689642, -0.028132385, 0.032260705, -0.018446295, 0.027803933, -0.07707924, -0.03096557, 0.00011443212, -0.0030657616, 0.014997327, -0.02013993, -0.010856078, -0.04718212, -0.00220697, -0.038141757, 0.012053017, -0.006264984, 0.04132065, 0.030020077, -0.009648787, -0.08291469, 0.031088402, -0.0055105407, 0.038928106, 0.09567269, -0.06545646, 0.014758843, -0.0076212618, -0.011586025, 0.006633285, 0.047722176, -0.02884411, -0.014966244, 0.005581196, -0.026660832, -0.021246316, 0.024245355, 0.06579296, 0.013766248, -0.020755317, -0.020285103, -0.043904163, -0.008092939, -0.079434454, -0.0062852763, -0.017899001, 0.044282112, 0.00476942, 0.011804391, -0.037244253, -0.036605947, 0.07632938, -0.030710464, 0.024843965, 0.034585446, 0.039770942, 0.0012431715, 0.04464095, -0.044297054, -0.042016122, -0.10283358, -0.0051937974, 0.011922596, -0.06329472, 0.03272134, 0.09449485, 0.0007038325, 0.019775068, 0.0057402193, -0.0062486073, -0.021324879, 0.020933796, -0.0018087287, 0.04598472, -0.042846415, 0.0032064754, -0.051261496, 0.061804477, 0.011057814, 0.038328324, 0.049931698, 0.005697765, 0.0062235007, 0.04094949, 0.011752371, 0.10192544, -0.01243403, 0.027922945, 0.036244784, -0.04156809, 0.09342277, -0.017223654, -0.0053121545, 0.0037630624, 0.01942488, -0.014338693, -0.01409534, -0.046128053, 0.029135892, 0.024738956, -0.0009798594, -0.05585021, -0.029796056, -0.00753753, 0.028716668, 0.017770182, -0.07188299, -0.048662543, -0.008774801, -0.022303376, 0.022265006, -0.027668579, 0.06194988, -0.055415675, 0.003288105, -0.031877484, 0.04046629, -0.0041070646, -0.0070924317, -0.005929042, 0.038992073, -0.0020153709, 0.040911596, 0.021059228, 0.007445994, -0.012237798, 0.012019143, -0.015631674, -0.027009, 0.040903404, -0.049067732, 0.026536843, -0.015484667, 0.06658825, 0.0068987254, -0.019007245, -0.0010244236, 0.04924899, 0.0033653018, -0.05465822, 0.025925921, 0.010840735, 0.019169949, 0.006122599, -0.032609552, 0.020006206, -0.01170148, -0.016322799, 0.007700651, -0.00836322, 0.0170394, -0.016769528, -0.0037159414, -0.005513138, 0.016008422, 0.009125709, -0.00138899, 0.04833421, 0.04610187, -0.020640664, 0.040556934, -0.017390836, 0.06183593, 0.00081108295, -0.041588247, -0.055235937, 0.011844637, 0.04907072, 0.009605561, 0.01177441, -0.0044095893, -0.0031115825, 0.017299814, -0.018385233, 0.0067453342, 0.00937401, -0.0071041286, 0.048608243, -0.011630161, 0.0062665856, 0.0032364083, -0.042992752, -0.020809794, 0.009860618, -0.02894594, 0.01897035, 0.042663023, -0.05229777, -0.027973184, 0.036035076, 0.01806709, 0.016328532, -0.019433167, -0.030896025, 0.05165891, -0.014043107, -0.011104985, 0.0351596, 0.0032814264, 0.042896967, -0.006126224, -0.0034738283, 0.012086968, 0.0375422, 0.0029994338, -0.05713711, -0.014024311, -0.060559414, -0.0035189197, -0.02003816, -0.0024746927, 0.04749309, 0.043660115, -0.05525647, 0.0037826877, -0.013970296, -0.008283592, -0.0033858991, 0.044653744, -0.06905693, 0.016987776, 0.024689903, -0.018849159, 0.06471993, -0.03209517, -0.012274448, 0.04969325, 0.03478025, 0.061522547, -0.05635405, -0.04693174, -0.046142172, 0.041133057, -0.06767319, -0.024371004, 0.02808511, -0.01664956, 0.020199332, -0.023629177, 0.02998218, 0.0076807216, -0.04407554, 0.00867406, -0.04957586, 0.014458079, -0.0068211607, 0.07653292, 0.013116131, -0.076485634, 0.026646826, -0.0065858094, -0.022441901, -0.034758274, 0.05861829, 0.0079881335, 0.041814823, -0.06992198, 0.0054150326, 0.0768808, -0.040069107, 0.022033079, 0.032994486, 0.0497385, 0.050856415, 0.027309133, 0.029308379, -0.03823064, 0.03282107, 0.011732973, 0.017224679, 0.05437938, 0.034066413, -0.007320778, 0.0029000961, 0.076388195, -0.016578075, 0.016499922, -0.069372766, -0.044288196, -0.023522215, 0.017446274, 0.034341596, -0.04083634, 0.018475669, 0.01307298, -0.030532613, 0.003200738, 0.05165182, -0.018093333, -0.007998051, 0.0022939423, -0.019729206, -0.043499634, -0.060922347, 0.084615014, 0.013213444, 0.039922252, -0.024299653, -0.037645172, 0.013850538, -0.0986581, 0.034294803, -0.04071812, -0.055841483, -0.00078221713, -0.0077464464, -0.012836462, 0.0042591766, -0.024714528, 0.011361975, -0.049862843, 0.014808281, -0.046937127, 0.07689841, -0.034688797, 0.014056977, 0.023830459, -0.023037221, 0.05009095, 0.023276433, -0.036674272, 0.0022519017, -0.009490272, 0.010584679, 0.0312068, -0.0274326, -0.02118456, 0.027516304, -0.027574366, 0.041349508, 0.032754675, -0.0369047, -0.025714818, -0.013775387, -0.056456123, 0.022530977, -0.020046744, 0.020214736, 0.019383337, -0.036903717, -0.016126284, -0.112193145, 0.05992413, -0.04801174, 0.0023643647, 0.014181601, 0.0014563452, 0.03998607, -0.015507363, 0.02134205, 0.025109258, 0.027871069, -0.0026332631, 0.019587878, -0.007014621, 0.0014957517, -0.009915231, -0.040314086, -0.010228143, 0.027873844, -0.09414795, 0.037290074, -0.020524476, -0.0015744471, -0.0027202256, 0.01000449, -0.024906073, -0.0070711966, 0.047096875, 0.078782864, -0.0013299551, -0.09215365, -0.01701658, -0.0113859065, 0.041975033, 0.033922486, 0.058304004, -0.010383922, 0.05210767, -0.020862311, 0.03513095, -0.076182805, -0.044525966, -0.051030084, -0.067459546, 0.020845866, -0.016399411, -0.0015835157, -0.044961873, 0.010039162, -0.006007793, -0.07208076, -0.062536314, -0.021511992, -0.05075232, 0.022780888, 0.018615097, -0.0038213246, -0.047422998, 0.048880745, 0.06952777, 0.02065618, -0.0040345225, 0.03775801, 0.010801913, -0.020207295, 0.028474195, 0.012068499, -0.03242112, 0.029786967, -0.025482435, 0.012005003, -0.009204893, -0.015464512, -0.026507169, -0.004393288, -0.025645938, -0.008149547, 0.03308221, 0.005578356, 0.04638518, -0.029539233, 0.07825038, 0.0031462687, -0.015040519, -0.010272209, 0.030465094, 0.005880402, -0.047361463, -0.065019734, -0.036803015, -0.044883046, -0.02739899, 0.040702865, 0.014714999, -0.048275255, -0.0033758667, -0.029347317, 0.026339423, 0.07875171, 0.0069593303, 0.06534449, 0.033954065, -0.034613848, 0.024543542, 0.044616338, -0.005548053, 0.048411205, 0.005011548, -0.0063090846, 0.05169009, -0.025942279, -0.047747288, -0.057653144, 0.0103794, -0.029119896, 0.03197949, 0.02815865, -0.048219077, -0.057045415, 0.037882898, -0.07150325, -0.0013539288, 0.025706504, 0.03322466, 0.034600444, 0.046806917, -0.003020832, -0.027908226, 0.0022708054, -0.0148583045, 0.03029568, 0.02150407, 0.0037807599, -0.03874552, -0.042657297, -0.03062884, -0.09146865, 0.038497258, 0.00425647, 0.023880444, 0.034882244, -0.0014225867, 0.017561946, -0.0017776758, 0.04133416, 0.019300802, -0.023230476, 0.077770896, -0.008981957, -0.046419956, -0.020920618, -0.044814367, 0.05569209, -0.025610829]\n"
     ]
    }
   ],
   "source": [
    "# This example avoids any space-specific terminology to see if the model avoids\n",
    "# biases towards specific jargon.\n",
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "embedded = embed_fn(new_text)\n",
    "print(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "sci.crypt: 0.01%\n",
      "sci.electronics: 0.44%\n",
      "sci.med: 0.09%\n",
      "sci.space: 99.47%\n"
     ]
    }
   ],
   "source": [
    "# Remember that the model takes embeddings as input, and the input must be batched,\n",
    "# so here they are passed as a list to provide a batch of 1.\n",
    "inp = np.array([embedded])\n",
    "[result] = classifier.predict(inp)\n",
    "\n",
    "for idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n",
    "    print(f\"{category}: {result[idx] * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
